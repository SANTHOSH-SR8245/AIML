{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SANTHOSH-SR8245/AIML/blob/main/naive_bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB,ComplementNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/kidney_disease_updated.csv\")\n",
        "\n",
        "# Check target column name (assuming \"classification\" or \"target\")\n",
        "print(df.columns)\n",
        "\n",
        "# Let's assume target column is \"classification\"\n",
        "X = df.drop(columns=[\"classification\"])\n",
        "y = df[\"classification\"]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Gaussian Naive Bayes (with scaling)\n",
        "# -------------------------------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train_scaled, y_train)\n",
        "y_pred_gnb = gnb.predict(X_test_scaled)\n",
        "\n",
        "print(\"GaussianNB Accuracy:\", accuracy_score(y_test, y_pred_gnb))\n",
        "print(classification_report(y_test, y_pred_gnb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ertHAj1U4Cij",
        "outputId": "4b6946e2-97dd-4c97-ce9e-43615af04efd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'bgr',\n",
            "       'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc', 'htn', 'dm', 'cad',\n",
            "       'appet', 'pe', 'ane', 'classification'],\n",
            "      dtype='object')\n",
            "GaussianNB Accuracy: 0.95\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.92      0.96        76\n",
            "           1       0.88      1.00      0.94        44\n",
            "\n",
            "    accuracy                           0.95       120\n",
            "   macro avg       0.94      0.96      0.95       120\n",
            "weighted avg       0.96      0.95      0.95       120\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Multinomial Naive Bayes (needs non-negative data)\n",
        "# -------------------------------\n",
        "# Shift data to positive values for multinomial\n",
        "X_train_pos = X_train - X_train.min().min()\n",
        "X_test_pos = X_test - X_train.min().min()\n",
        "\n",
        "mnb = MultinomialNB()\n",
        "mnb.fit(X_train_pos, y_train)\n",
        "y_pred_mnb = mnb.predict(X_test_pos)\n",
        "\n",
        "print(\"MultinomialNB Accuracy:\", accuracy_score(y_test, y_pred_mnb))\n",
        "print(classification_report(y_test, y_pred_mnb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bF0aJqCv4hqA",
        "outputId": "69fbf593-9d6e-4c48-ab74-f48232c335f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultinomialNB Accuracy: 0.9416666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.91      0.95        76\n",
            "           1       0.86      1.00      0.93        44\n",
            "\n",
            "    accuracy                           0.94       120\n",
            "   macro avg       0.93      0.95      0.94       120\n",
            "weighted avg       0.95      0.94      0.94       120\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnb = ComplementNB()\n",
        "cnb.fit(X_train_pos, y_train)\n",
        "y_pred_cnb = cnb.predict(X_test_pos)\n",
        "\n",
        "print(\"\\nComplementNB Accuracy:\", accuracy_score(y_test, y_pred_cnb))\n",
        "print(classification_report(y_test, y_pred_cnb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVmrByjp5c8V",
        "outputId": "f8c2c5d8-352e-4908-b55f-2e4ce9fdd092"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ComplementNB Accuracy: 0.9416666666666667\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.91      0.95        76\n",
            "           1       0.86      1.00      0.93        44\n",
            "\n",
            "    accuracy                           0.94       120\n",
            "   macro avg       0.93      0.95      0.94       120\n",
            "weighted avg       0.95      0.94      0.94       120\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 1. Import libraries\n",
        "# -----------------------------\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/kidney_disease_updated.csv\")\n",
        "# -----------------------------\n",
        "# 2. List of categorical columns\n",
        "# -----------------------------\n",
        "cat_columns = ['cad', 'appet', 'pe', 'ane', 'htn', 'dm']  # features\n",
        "target_col = 'classification'  # target\n",
        "\n",
        "# -----------------------------\n",
        "# 3. Handle missing values and encode\n",
        "# -----------------------------\n",
        "# Use mode for imputation (most frequent value)\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "df[cat_columns + [target_col]] = imputer.fit_transform(df[cat_columns + [target_col]])\n",
        "\n",
        "# Encode all categorical columns\n",
        "label_encoders = {}\n",
        "for col in cat_columns + [target_col]:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le  # save encoder for later decoding\n",
        "\n",
        "# -----------------------------\n",
        "# 4. Split dataset into train/test\n",
        "# -----------------------------\n",
        "X = df[cat_columns]\n",
        "y = df[target_col]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# -----------------------------\n",
        "# 5. Train Categorical Naive Bayes\n",
        "# -----------------------------\n",
        "model = CategoricalNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# -----------------------------\n",
        "# 6. Make predictions\n",
        "# -----------------------------\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# -----------------------------\n",
        "# 7. Evaluate model\n",
        "# -----------------------------\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "F28_ZCkh6odN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86231dee-3670-4fc4-cfaf-6bd15696f443"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9\n",
            "\n",
            "Confusion Matrix:\n",
            " [[55 10]\n",
            " [ 0 35]]\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.85      0.92        65\n",
            "           1       0.78      1.00      0.88        35\n",
            "\n",
            "    accuracy                           0.90       100\n",
            "   macro avg       0.89      0.92      0.90       100\n",
            "weighted avg       0.92      0.90      0.90       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Load dataset\n",
        "# -------------------------------\n",
        "df = pd.read_csv(\"/content/kidney_disease_updated.csv\")\n",
        "\n",
        "# Assume target column is \"classification\"\n",
        "X = df.drop(columns=[\"classification\"])\n",
        "y = df[\"classification\"]\n",
        "\n",
        "# Laplace smoothing alpha can be tuned (try 0.5 or 1.0)\n",
        "bnb = BernoulliNB(alpha=0.5)\n",
        "bnb.fit(X_train, y_train)\n",
        "y_pred_bnb = bnb.predict(X_test)\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Evaluation\n",
        "# -------------------------------\n",
        "print(\"BernoulliNB Accuracy:\", accuracy_score(y_test, y_pred_bnb))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_bnb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPJjr3ll-bk1",
        "outputId": "f668fcb8-081f-428a-defa-68bd07188520"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BernoulliNB Accuracy: 0.9\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.85      0.92        65\n",
            "           1       0.78      1.00      0.88        35\n",
            "\n",
            "    accuracy                           0.90       100\n",
            "   macro avg       0.89      0.92      0.90       100\n",
            "weighted avg       0.92      0.90      0.90       100\n",
            "\n"
          ]
        }
      ]
    }
  ]
}